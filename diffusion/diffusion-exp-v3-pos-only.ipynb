{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "path = os.path.abspath(os.path.join('..'))\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, torch.Size([78, 35]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusion.data_loaders.spinkick_pos_only_dataset import SpinkickPosOnlyDataset\n",
    "dataset = SpinkickPosOnlyDataset(\"/home/kenji/Fyp/DeepMimic_mujoco/diffusion/data/motions/humanoid3d_spinkick.txt\")\n",
    "len(dataset), dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.8251,  ..., -0.5877, -0.5578, -0.1123],\n",
       "        [-0.0098, -0.0053,  0.8223,  ..., -0.6034, -0.5496, -0.1377],\n",
       "        [-0.0205, -0.0135,  0.8187,  ..., -0.6073, -0.5372, -0.1672],\n",
       "        ...,\n",
       "        [ 0.4499, -0.1250,  0.7884,  ..., -0.6189,  0.1019, -0.4792],\n",
       "        [ 0.4598, -0.1251,  0.8026,  ..., -0.6567, -0.0243, -0.4099],\n",
       "        [ 0.4689, -0.1252,  0.8251,  ..., -0.6718, -0.1104, -0.3359]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # not used in the final model\n",
    "        x = x + self.pe[:x.shape[0], :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TimestepEmbedder(nn.Module):\n",
    "    def __init__(self, latent_dim, sequence_pos_encoder):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.sequence_pos_encoder = sequence_pos_encoder\n",
    "\n",
    "        time_embed_dim = self.latent_dim\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim, time_embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_embed_dim, time_embed_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, timesteps):\n",
    "        return self.time_embed(self.sequence_pos_encoder.pe[timesteps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotionTransformer(nn.Module):\n",
    "    def __init__(self, pos_dim, latent_dim=256, ff_size=1024, num_layers=8, num_heads=4, dropout=0.1, activation=\"gelu\"):\n",
    "        super(MotionTransformer, self).__init__()\n",
    "        \n",
    "        # self.nfeats = nfeats\n",
    "        self.pos_dim = pos_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.ff_size = ff_size  \n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.posEmbedding = nn.Linear(self.pos_dim, self.latent_dim)\n",
    "        self.sequence_pos_encoder = PositionalEncoding(self.latent_dim, self.dropout)\n",
    "        self.embed_timestep = TimestepEmbedder(self.latent_dim, self.sequence_pos_encoder)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=self.latent_dim, nhead=num_heads, \n",
    "                                                    dim_feedforward=ff_size, dropout=dropout, activation=activation, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "\n",
    "        # Output Linear Layer\n",
    "        self.posOutEmbedding = nn.Linear(self.latent_dim, self.pos_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, timesteps, y=None, verbose=False):\n",
    "        \"\"\"\n",
    "        x: [batch_size, max_frames, n_feats], denoted x_t in the paper\n",
    "        timesteps: [batch_size] (int)\n",
    "        \"\"\"\n",
    "        # x: [batch_size, seq_len, nfeats]\n",
    "        emb = self.embed_timestep(timesteps)  # [bs, n_frames, time_embed_dim]\n",
    "        if verbose:\n",
    "            print(\"Emb\", emb.shape)\n",
    "            print(emb)\n",
    "\n",
    "        x = self.posEmbedding(x) # [bs, n_frames, n_dim]\n",
    "        if verbose:\n",
    "            print(\"Frame Embedding\", x.shape)\n",
    "            print(x)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        # adding the timestep embed\n",
    "        xseq = torch.cat((emb, x), axis=1)  # [bs, n_frames+1, n_dim]\n",
    "        if verbose:\n",
    "            print(\"Concat x and zkx\", xseq.shape)\n",
    "            print(xseq)\n",
    "\n",
    "        xseq = self.sequence_pos_encoder(xseq)  # [bs, n_frames+1, n_dim]\n",
    "        if verbose:\n",
    "            print(\"Sequence Pos Encoder\", xseq.shape)\n",
    "            print(xseq)\n",
    "\n",
    "        output = self.transformer_encoder(xseq)[:, 1:, :]  # , src_key_padding_mask=~maskseq)  # [bs, n_frames, n_dim]\n",
    "        if verbose:\n",
    "            print(\"Transformer Encoder\", output.shape)\n",
    "            print(output)\n",
    "\n",
    "        # Output Linear\n",
    "        output = self.posOutEmbedding(output)\n",
    "        if verbose:\n",
    "            print(\"Output Embedding\", output.shape)\n",
    "            print(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 1\n",
    "dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, drop_last=True)\n",
    "\n",
    "pos_dim = dataset[0].shape[1]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MotionTransformer(pos_dim=pos_dim, latent_dim=128, ff_size=512, num_layers=8, num_heads=4, dropout=0.1, activation=\"gelu\").to(device)\n",
    "\n",
    "pos_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 78, 35])\n",
      "Emb torch.Size([1, 1, 128])\n",
      "tensor([[[-5.2326e-02,  1.0404e-01,  1.1141e-01, -3.1471e-01,  6.5154e-02,\n",
      "          -6.4290e-02,  6.9357e-02,  1.5860e-01,  6.4102e-03,  1.9527e-01,\n",
      "          -1.3651e-01, -1.1225e-01, -1.5034e-01, -3.7038e-02, -4.7231e-02,\n",
      "          -1.3426e-01,  2.6856e-02,  7.7447e-02, -1.1523e-02, -2.8833e-02,\n",
      "          -6.0362e-02, -8.5810e-02,  2.4798e-02, -2.7860e-02, -1.0549e-01,\n",
      "          -4.8245e-02,  7.1338e-02, -1.3930e-01,  6.5066e-02,  1.7957e-02,\n",
      "          -8.5926e-02, -1.7173e-01,  1.8378e-01,  5.7447e-02,  1.1668e-01,\n",
      "           9.6384e-02,  2.3573e-02,  3.6470e-02, -1.2993e-01,  8.9927e-03,\n",
      "          -9.6132e-02, -1.1727e-02,  1.2519e-01, -6.4635e-02, -1.1738e-01,\n",
      "          -2.1501e-02, -1.1976e-02, -6.5760e-03, -2.4115e-01,  5.4326e-02,\n",
      "          -5.8885e-02, -1.9089e-04, -1.4354e-01, -2.0395e-01, -1.4770e-01,\n",
      "           9.0752e-02, -1.0371e-01,  2.7519e-02, -8.9220e-02, -1.0204e-01,\n",
      "          -1.5541e-01, -1.7172e-01,  2.4143e-01,  1.0461e-01, -1.2051e-01,\n",
      "          -1.1775e-01, -1.6320e-01, -5.6349e-02,  3.3813e-02, -6.4427e-02,\n",
      "           5.7491e-02, -1.0779e-01,  7.1385e-02, -3.8741e-02, -1.4270e-01,\n",
      "           1.0065e-01,  4.0803e-02, -8.8635e-02, -2.5867e-02, -5.8004e-02,\n",
      "          -7.9664e-02, -1.1523e-01, -9.7123e-02, -8.9231e-02, -9.8896e-03,\n",
      "           1.2077e-01,  2.7925e-02, -8.6117e-02, -2.5987e-01,  8.0156e-02,\n",
      "          -1.0635e-01,  1.5450e-02,  1.8783e-01, -5.1110e-02, -1.1589e-01,\n",
      "          -1.1793e-01, -2.1506e-01,  1.4644e-01, -1.6232e-01, -1.6824e-01,\n",
      "          -3.4761e-02, -1.2336e-01, -1.4377e-01,  1.5328e-01,  8.4194e-02,\n",
      "          -8.2757e-02,  1.0169e-01, -3.4153e-02, -7.8312e-02,  6.3451e-02,\n",
      "          -1.5906e-03, -1.0278e-01, -4.4542e-02, -9.1546e-02, -2.6699e-03,\n",
      "           1.5814e-02,  1.5850e-01, -1.2526e-01,  9.6483e-02,  8.8745e-03,\n",
      "           2.4926e-01,  3.6401e-02,  3.8316e-02,  1.0772e-01, -7.9027e-03,\n",
      "          -1.7135e-01, -3.0274e-03, -2.0594e-01]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Frame Embedding torch.Size([1, 78, 128])\n",
      "tensor([[[-0.1684, -0.0211,  0.1235,  ..., -0.2352,  0.0634, -0.3492],\n",
      "         [-0.1394,  0.0065,  0.1385,  ..., -0.2639,  0.0848, -0.3741],\n",
      "         [-0.1244,  0.0243,  0.1402,  ..., -0.2924,  0.1018, -0.4082],\n",
      "         ...,\n",
      "         [-0.2757, -0.1142,  0.1122,  ..., -0.1759,  0.2364, -0.4951],\n",
      "         [-0.2687, -0.1108,  0.0824,  ..., -0.1526,  0.2264, -0.4841],\n",
      "         [-0.2587, -0.1241,  0.0505,  ..., -0.1478,  0.2185, -0.4781]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Concat x and zkx torch.Size([1, 79, 128])\n",
      "tensor([[[-0.0523,  0.1040,  0.1114,  ..., -0.1714, -0.0030, -0.2059],\n",
      "         [-0.1684, -0.0211,  0.1235,  ..., -0.2352,  0.0634, -0.3492],\n",
      "         [-0.1394,  0.0065,  0.1385,  ..., -0.2639,  0.0848, -0.3741],\n",
      "         ...,\n",
      "         [-0.2757, -0.1142,  0.1122,  ..., -0.1759,  0.2364, -0.4951],\n",
      "         [-0.2687, -0.1108,  0.0824,  ..., -0.1526,  0.2264, -0.4841],\n",
      "         [-0.2587, -0.1241,  0.0505,  ..., -0.1478,  0.2185, -0.4781]]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "Sequence Pos Encoder torch.Size([1, 79, 128])\n",
      "tensor([[[-0.0581,  1.2267,  0.1238,  ...,  0.9207, -0.0034,  0.8823],\n",
      "         [-0.1871,  1.0876,  0.1372,  ...,  0.8498,  0.0704,  0.7231],\n",
      "         [-0.0000,  1.1183,  0.1539,  ...,  0.8179,  0.0942,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.9843,  0.1247,  ...,  0.9156,  0.2627,  0.0000],\n",
      "         [-0.2985,  0.9880,  0.0915,  ...,  0.9415,  0.2515,  0.5733],\n",
      "         [-0.2874,  0.9732,  0.0561,  ...,  0.9469,  0.2427,  0.5798]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "Transformer Encoder torch.Size([1, 78, 128])\n",
      "tensor([[[ 0.1337,  0.1416,  0.1085,  ..., -0.3361,  0.0339, -1.5372],\n",
      "         [-0.0754,  0.1112, -0.1928,  ..., -0.5087, -0.3409, -1.3498],\n",
      "         [-0.4978,  0.2844, -0.1192,  ..., -0.1788, -0.0661, -1.6720],\n",
      "         ...,\n",
      "         [ 0.0907,  0.2632, -0.2015,  ..., -0.2004, -0.0596, -1.5193],\n",
      "         [-0.1432,  0.0704, -0.1641,  ..., -0.2774,  0.1952, -1.4725],\n",
      "         [ 0.4159, -0.1272, -0.2654,  ..., -0.0093, -0.0754, -1.2107]]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Output Embedding torch.Size([1, 78, 35])\n",
      "tensor([[[-0.9707, -0.1390, -0.2952,  ..., -0.3470,  0.9036, -0.0292],\n",
      "         [-1.0944, -0.2145, -0.2623,  ..., -0.5445,  0.7846, -0.1314],\n",
      "         [-1.0212,  0.1327,  0.0110,  ..., -0.3780,  0.8497, -0.0573],\n",
      "         ...,\n",
      "         [-1.0828,  0.0332, -0.0064,  ..., -0.1906,  1.1861,  0.0479],\n",
      "         [-1.2035,  0.1884, -0.1515,  ..., -0.2537,  0.9267, -0.1362],\n",
      "         [-1.0063, -0.1138,  0.0423,  ..., -0.2226,  0.6095,  0.0384]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 78, 35])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = dataset[0].unsqueeze(0).to(device)    \n",
    "print(test_sample.shape)\n",
    "\n",
    "res = model(test_sample, torch.tensor([0]).to(device), verbose=True)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion.diffusion import gaussian_diffusion as gd\n",
    "from diffusion.diffusion.respace import SpacedDiffusion, space_timesteps\n",
    "\n",
    "def create_gaussian_diffusion(\n",
    "        diffusion_steps, # number eg 1000\n",
    "        noise_schedule, # can be 'linear', 'cosine'\n",
    "        sigma_small, # default True\n",
    "        lambda_vel, lambda_rcxyz, lambda_fc # for geometric loss, we don't have fc, default 1 for rest\n",
    "        ):\n",
    "    # default params\n",
    "    predict_xstart = True  # we always predict x_start (a.k.a. x0), that's our deal!\n",
    "    steps = diffusion_steps\n",
    "    scale_beta = 1.  # no scaling\n",
    "    timestep_respacing = ''  # can be used for ddim sampling, we don't use it.\n",
    "    learn_sigma = False\n",
    "    rescale_timesteps = False\n",
    "\n",
    "    betas = gd.get_named_beta_schedule(noise_schedule, steps, scale_beta)\n",
    "    loss_type = gd.LossType.MSE\n",
    "\n",
    "    if not timestep_respacing:\n",
    "        timestep_respacing = [steps]\n",
    "\n",
    "    return SpacedDiffusion(\n",
    "        use_timesteps=space_timesteps(steps, timestep_respacing),\n",
    "        betas=betas,\n",
    "        model_mean_type=(\n",
    "            gd.ModelMeanType.EPSILON if not predict_xstart else gd.ModelMeanType.START_X\n",
    "        ),\n",
    "        model_var_type=(\n",
    "            (\n",
    "                gd.ModelVarType.FIXED_LARGE\n",
    "                if not sigma_small\n",
    "                else gd.ModelVarType.FIXED_SMALL\n",
    "            )\n",
    "            if not learn_sigma\n",
    "            else gd.ModelVarType.LEARNED_RANGE\n",
    "        ),\n",
    "        loss_type=loss_type,\n",
    "        rescale_timesteps=rescale_timesteps,\n",
    "        lambda_vel=lambda_vel,\n",
    "        lambda_rcxyz=lambda_rcxyz,\n",
    "        lambda_fc=lambda_fc,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MotionTransformer(pos_dim=pos_dim, latent_dim=128, ff_size=512, num_layers=4, num_heads=4, dropout=0.1, activation=\"gelu\").to(device)\n",
    "diffusion = create_gaussian_diffusion(diffusion_steps=1000, noise_schedule=\"cosine\", sigma_small=True, lambda_vel=0.5, lambda_rcxyz=0.5, lambda_fc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultArgs:\n",
    "    def __init__(self, save_dir, model_path, eval_model_path):\n",
    "        # Base options\n",
    "        self.cuda = True\n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.seed = 10\n",
    "        self.batch_size = 1\n",
    "\n",
    "        # Diffusion options\n",
    "        self.noise_schedule = 'cosine'\n",
    "        self.diffusion_steps = 1000\n",
    "        self.sigma_small = True\n",
    "\n",
    "        # Model options\n",
    "        self.arch = 'trans_enc'\n",
    "        self.emb_trans_dec = False\n",
    "        self.layers = 4\n",
    "        self.latent_dim = 128\n",
    "        self.cond_mask_prob = 0.1\n",
    "        self.lambda_rcxyz = 1.0\n",
    "        self.lambda_vel = 1.0\n",
    "        self.lambda_fc = 1.0\n",
    "        self.unconstrained = False  # This is inferred from the 'action' parameter\n",
    "\n",
    "        # Data options\n",
    "        self.dataset = 'humanml'\n",
    "        self.data_dir = \"\"\n",
    "\n",
    "        # Training options\n",
    "        self.save_dir = save_dir\n",
    "        self.overwrite = False\n",
    "        self.train_platform_type = 'NoPlatform'\n",
    "        self.lr = 1e-4\n",
    "        self.weight_decay = 0.0\n",
    "        self.lr_anneal_steps = 0\n",
    "        self.eval_batch_size = 16\n",
    "        self.eval_split = 'test'\n",
    "        self.eval_during_training = False\n",
    "        self.eval_rep_times = 3\n",
    "        self.eval_num_samples = 1000\n",
    "        self.log_interval = 1000\n",
    "        self.save_interval = 4000\n",
    "        self.num_steps = 20000\n",
    "        # self.num_frames = 29\n",
    "        self.resume_checkpoint = \"\"\n",
    "\n",
    "        # Sampling options\n",
    "        self.model_path = model_path\n",
    "        self.output_dir = ''\n",
    "        self.num_samples = 10\n",
    "        self.num_repetitions = 3\n",
    "        self.guidance_param = 2.5\n",
    "\n",
    "        # Generate options\n",
    "        self.motion_length = 6.0\n",
    "        self.input_text = ''\n",
    "        self.action_file = ''\n",
    "        self.text_prompt = ''\n",
    "        self.action_name = ''\n",
    "\n",
    "        # Edit options\n",
    "        self.edit_mode = 'in_between'\n",
    "        self.text_condition = ''\n",
    "        self.prefix_end = 0.25\n",
    "        self.suffix_start = 0.75\n",
    "\n",
    "        # Evaluation options\n",
    "        self.eval_model_path = eval_model_path\n",
    "        self.eval_mode = 'wo_mm'\n",
    "        self.eval_guidance_param = 2.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expname = \"model-v3-same-pos-data-more-dims-epochs\"\n",
    "\n",
    "args = DefaultArgs(save_dir=f\"/home/kenji/Fyp/DeepMimic_mujoco/diffusion/logs/{expname}\", model_path=f\"/home/kenji/Fyp/DeepMimic_mujoco/diffusion/logs/{expname}/model.pt\", eval_model_path=f\"/home/kenji/Fyp/DeepMimic_mujoco/diffusion/logs/{expname}/model.pt\")\n",
    "args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 255      |\n",
      "| loss        | 239      |\n",
      "| loss_q0     | 32       |\n",
      "| loss_q1     | 92.4     |\n",
      "| loss_q2     | 295      |\n",
      "| loss_q3     | 519      |\n",
      "| param_norm  | 37.7     |\n",
      "| pos_loss    | 239      |\n",
      "| pos_loss_q0 | 32       |\n",
      "| pos_loss_q1 | 92.4     |\n",
      "| pos_loss_q2 | 295      |\n",
      "| pos_loss_q3 | 519      |\n",
      "| samples     | 1        |\n",
      "| step        | 0        |\n",
      "--------------------------\n",
      "step[0]: loss[239.48538]\n",
      "saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [00:00<01:17, 12.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping evaluation for now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 579      |\n",
      "| loss        | 337      |\n",
      "| loss_q0     | 172      |\n",
      "| loss_q1     | 242      |\n",
      "| loss_q2     | 396      |\n",
      "| loss_q3     | 549      |\n",
      "| param_norm  | 54.7     |\n",
      "| pos_loss    | 337      |\n",
      "| pos_loss_q0 | 172      |\n",
      "| pos_loss_q1 | 242      |\n",
      "| pos_loss_q2 | 396      |\n",
      "| pos_loss_q3 | 549      |\n",
      "| samples     | 1e+03    |\n",
      "| step        | 1e+03    |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<03:13,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[1000]: loss[337.12066]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 34.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 2/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 366      |\n",
      "| loss        | 240      |\n",
      "| loss_q0     | 51.2     |\n",
      "| loss_q1     | 117      |\n",
      "| loss_q2     | 306      |\n",
      "| loss_q3     | 513      |\n",
      "| param_norm  | 55.1     |\n",
      "| pos_loss    | 240      |\n",
      "| pos_loss_q0 | 51.2     |\n",
      "| pos_loss_q1 | 117      |\n",
      "| pos_loss_q2 | 306      |\n",
      "| pos_loss_q3 | 513      |\n",
      "| samples     | 2e+03    |\n",
      "| step        | 2e+03    |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<03:16,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[2000]: loss[239.63360]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 34.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 3/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 324      |\n",
      "| loss        | 239      |\n",
      "| loss_q0     | 34.2     |\n",
      "| loss_q1     | 94.8     |\n",
      "| loss_q2     | 295      |\n",
      "| loss_q3     | 502      |\n",
      "| param_norm  | 55.3     |\n",
      "| pos_loss    | 239      |\n",
      "| pos_loss_q0 | 34.2     |\n",
      "| pos_loss_q1 | 94.8     |\n",
      "| pos_loss_q2 | 295      |\n",
      "| pos_loss_q3 | 502      |\n",
      "| samples     | 3e+03    |\n",
      "| step        | 3e+03    |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<03:07,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[3000]: loss[238.70622]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 34.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 4/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 296      |\n",
      "| loss        | 227      |\n",
      "| loss_q0     | 26.2     |\n",
      "| loss_q1     | 80.7     |\n",
      "| loss_q2     | 286      |\n",
      "| loss_q3     | 499      |\n",
      "| param_norm  | 55.5     |\n",
      "| pos_loss    | 227      |\n",
      "| pos_loss_q0 | 26.2     |\n",
      "| pos_loss_q1 | 80.7     |\n",
      "| pos_loss_q2 | 286      |\n",
      "| pos_loss_q3 | 499      |\n",
      "| samples     | 4e+03    |\n",
      "| step        | 4e+03    |\n",
      "--------------------------\n",
      "step[4000]: loss[227.49099]\n",
      "saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:00<00:58, 16.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping evaluation for now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 34.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 5/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 284      |\n",
      "| loss        | 217      |\n",
      "| loss_q0     | 23.5     |\n",
      "| loss_q1     | 83       |\n",
      "| loss_q2     | 283      |\n",
      "| loss_q3     | 500      |\n",
      "| param_norm  | 55.6     |\n",
      "| pos_loss    | 217      |\n",
      "| pos_loss_q0 | 23.5     |\n",
      "| pos_loss_q1 | 83       |\n",
      "| pos_loss_q2 | 283      |\n",
      "| pos_loss_q3 | 500      |\n",
      "| samples     | 5e+03    |\n",
      "| step        | 5e+03    |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<02:57,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[5000]: loss[216.51297]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 34.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 6/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 260      |\n",
      "| loss        | 216      |\n",
      "| loss_q0     | 20.2     |\n",
      "| loss_q1     | 76.9     |\n",
      "| loss_q2     | 288      |\n",
      "| loss_q3     | 498      |\n",
      "| param_norm  | 55.7     |\n",
      "| pos_loss    | 216      |\n",
      "| pos_loss_q0 | 20.2     |\n",
      "| pos_loss_q1 | 76.9     |\n",
      "| pos_loss_q2 | 288      |\n",
      "| pos_loss_q3 | 498      |\n",
      "| samples     | 6e+03    |\n",
      "| step        | 6e+03    |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:00<00:55, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[6000]: loss[216.43259]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 34.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 7/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 249      |\n",
      "| loss        | 213      |\n",
      "| loss_q0     | 18.2     |\n",
      "| loss_q1     | 74.8     |\n",
      "| loss_q2     | 266      |\n",
      "| loss_q3     | 498      |\n",
      "| param_norm  | 55.8     |\n",
      "| pos_loss    | 213      |\n",
      "| pos_loss_q0 | 18.2     |\n",
      "| pos_loss_q1 | 74.8     |\n",
      "| pos_loss_q2 | 266      |\n",
      "| pos_loss_q3 | 498      |\n",
      "| samples     | 7e+03    |\n",
      "| step        | 7e+03    |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<03:12,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[7000]: loss[212.88204]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 33.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 8/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 243      |\n",
      "| loss        | 218      |\n",
      "| loss_q0     | 16.6     |\n",
      "| loss_q1     | 72.5     |\n",
      "| loss_q2     | 276      |\n",
      "| loss_q3     | 495      |\n",
      "| param_norm  | 55.9     |\n",
      "| pos_loss    | 218      |\n",
      "| pos_loss_q0 | 16.6     |\n",
      "| pos_loss_q1 | 72.5     |\n",
      "| pos_loss_q2 | 276      |\n",
      "| pos_loss_q3 | 495      |\n",
      "| samples     | 8e+03    |\n",
      "| step        | 8e+03    |\n",
      "--------------------------\n",
      "step[8000]: loss[218.12822]\n",
      "saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:00<01:10, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping evaluation for now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 34.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 9/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 239      |\n",
      "| loss        | 221      |\n",
      "| loss_q0     | 16.2     |\n",
      "| loss_q1     | 69.3     |\n",
      "| loss_q2     | 263      |\n",
      "| loss_q3     | 499      |\n",
      "| param_norm  | 56       |\n",
      "| pos_loss    | 221      |\n",
      "| pos_loss_q0 | 16.2     |\n",
      "| pos_loss_q1 | 69.3     |\n",
      "| pos_loss_q2 | 263      |\n",
      "| pos_loss_q3 | 499      |\n",
      "| samples     | 9e+03    |\n",
      "| step        | 9e+03    |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:00<01:08, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[9000]: loss[221.29635]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 34.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 10/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 229      |\n",
      "| loss        | 213      |\n",
      "| loss_q0     | 14.8     |\n",
      "| loss_q1     | 66.4     |\n",
      "| loss_q2     | 277      |\n",
      "| loss_q3     | 490      |\n",
      "| param_norm  | 56.1     |\n",
      "| pos_loss    | 213      |\n",
      "| pos_loss_q0 | 14.8     |\n",
      "| pos_loss_q1 | 66.4     |\n",
      "| pos_loss_q2 | 277      |\n",
      "| pos_loss_q3 | 490      |\n",
      "| samples     | 1e+04    |\n",
      "| step        | 1e+04    |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<02:58,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[10000]: loss[213.14098]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 34.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 11/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 224      |\n",
      "| loss        | 213      |\n",
      "| loss_q0     | 13.5     |\n",
      "| loss_q1     | 66.1     |\n",
      "| loss_q2     | 275      |\n",
      "| loss_q3     | 497      |\n",
      "| param_norm  | 56.2     |\n",
      "| pos_loss    | 213      |\n",
      "| pos_loss_q0 | 13.5     |\n",
      "| pos_loss_q1 | 66.1     |\n",
      "| pos_loss_q2 | 275      |\n",
      "| pos_loss_q3 | 497      |\n",
      "| samples     | 1.1e+04  |\n",
      "| step        | 1.1e+04  |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<03:06,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[11000]: loss[212.93577]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 34.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 12/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 222      |\n",
      "| loss        | 215      |\n",
      "| loss_q0     | 13.1     |\n",
      "| loss_q1     | 70.8     |\n",
      "| loss_q2     | 273      |\n",
      "| loss_q3     | 497      |\n",
      "| param_norm  | 56.2     |\n",
      "| pos_loss    | 215      |\n",
      "| pos_loss_q0 | 13.1     |\n",
      "| pos_loss_q1 | 70.8     |\n",
      "| pos_loss_q2 | 273      |\n",
      "| pos_loss_q3 | 497      |\n",
      "| samples     | 1.2e+04  |\n",
      "| step        | 1.2e+04  |\n",
      "--------------------------\n",
      "step[12000]: loss[214.68792]\n",
      "saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:00<00:59, 16.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping evaluation for now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 34.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 13/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 208      |\n",
      "| loss        | 211      |\n",
      "| loss_q0     | 12.3     |\n",
      "| loss_q1     | 65.2     |\n",
      "| loss_q2     | 275      |\n",
      "| loss_q3     | 497      |\n",
      "| param_norm  | 56.3     |\n",
      "| pos_loss    | 211      |\n",
      "| pos_loss_q0 | 12.3     |\n",
      "| pos_loss_q1 | 65.2     |\n",
      "| pos_loss_q2 | 275      |\n",
      "| pos_loss_q3 | 497      |\n",
      "| samples     | 1.3e+04  |\n",
      "| step        | 1.3e+04  |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<03:15,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[13000]: loss[210.86117]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 34.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 14/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 208      |\n",
      "| loss        | 214      |\n",
      "| loss_q0     | 11.9     |\n",
      "| loss_q1     | 62.3     |\n",
      "| loss_q2     | 268      |\n",
      "| loss_q3     | 498      |\n",
      "| param_norm  | 56.4     |\n",
      "| pos_loss    | 214      |\n",
      "| pos_loss_q0 | 11.9     |\n",
      "| pos_loss_q1 | 62.3     |\n",
      "| pos_loss_q2 | 268      |\n",
      "| pos_loss_q3 | 498      |\n",
      "| samples     | 1.4e+04  |\n",
      "| step        | 1.4e+04  |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:00<01:11, 13.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[14000]: loss[213.77416]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:30<00:00, 33.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 15/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 207      |\n",
      "| loss        | 217      |\n",
      "| loss_q0     | 11.9     |\n",
      "| loss_q1     | 62.3     |\n",
      "| loss_q2     | 272      |\n",
      "| loss_q3     | 495      |\n",
      "| param_norm  | 56.4     |\n",
      "| pos_loss    | 217      |\n",
      "| pos_loss_q0 | 11.9     |\n",
      "| pos_loss_q1 | 62.3     |\n",
      "| pos_loss_q2 | 272      |\n",
      "| pos_loss_q3 | 495      |\n",
      "| samples     | 1.5e+04  |\n",
      "| step        | 1.5e+04  |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:00<01:17, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[15000]: loss[216.69632]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 33.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 16/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 206      |\n",
      "| loss        | 210      |\n",
      "| loss_q0     | 11.1     |\n",
      "| loss_q1     | 66.1     |\n",
      "| loss_q2     | 269      |\n",
      "| loss_q3     | 497      |\n",
      "| param_norm  | 56.5     |\n",
      "| pos_loss    | 210      |\n",
      "| pos_loss_q0 | 11.1     |\n",
      "| pos_loss_q1 | 66.1     |\n",
      "| pos_loss_q2 | 269      |\n",
      "| pos_loss_q3 | 497      |\n",
      "| samples     | 1.6e+04  |\n",
      "| step        | 1.6e+04  |\n",
      "--------------------------\n",
      "step[16000]: loss[210.36960]\n",
      "saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:00<01:02, 15.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping evaluation for now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 34.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 17/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 199      |\n",
      "| loss        | 209      |\n",
      "| loss_q0     | 11.3     |\n",
      "| loss_q1     | 69       |\n",
      "| loss_q2     | 271      |\n",
      "| loss_q3     | 495      |\n",
      "| param_norm  | 56.6     |\n",
      "| pos_loss    | 209      |\n",
      "| pos_loss_q0 | 11.3     |\n",
      "| pos_loss_q1 | 69       |\n",
      "| pos_loss_q2 | 271      |\n",
      "| pos_loss_q3 | 495      |\n",
      "| samples     | 1.7e+04  |\n",
      "| step        | 1.7e+04  |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:00<00:58, 17.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[17000]: loss[209.33553]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 34.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 18/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 192      |\n",
      "| loss        | 209      |\n",
      "| loss_q0     | 10.7     |\n",
      "| loss_q1     | 63       |\n",
      "| loss_q2     | 270      |\n",
      "| loss_q3     | 496      |\n",
      "| param_norm  | 56.6     |\n",
      "| pos_loss    | 209      |\n",
      "| pos_loss_q0 | 10.7     |\n",
      "| pos_loss_q1 | 63       |\n",
      "| pos_loss_q2 | 270      |\n",
      "| pos_loss_q3 | 496      |\n",
      "| samples     | 1.8e+04  |\n",
      "| step        | 1.8e+04  |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<03:14,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[18000]: loss[209.17853]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 33.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 19/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 196      |\n",
      "| loss        | 214      |\n",
      "| loss_q0     | 10.3     |\n",
      "| loss_q1     | 66       |\n",
      "| loss_q2     | 280      |\n",
      "| loss_q3     | 496      |\n",
      "| param_norm  | 56.7     |\n",
      "| pos_loss    | 214      |\n",
      "| pos_loss_q0 | 10.3     |\n",
      "| pos_loss_q1 | 66       |\n",
      "| pos_loss_q2 | 280      |\n",
      "| pos_loss_q3 | 496      |\n",
      "| samples     | 1.9e+04  |\n",
      "| step        | 1.9e+04  |\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<03:16,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step[19000]: loss[213.73068]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 33.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 20/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 195      |\n",
      "| loss        | 214      |\n",
      "| loss_q0     | 10.4     |\n",
      "| loss_q1     | 63.4     |\n",
      "| loss_q2     | 277      |\n",
      "| loss_q3     | 495      |\n",
      "| param_norm  | 56.7     |\n",
      "| pos_loss    | 214      |\n",
      "| pos_loss_q0 | 10.4     |\n",
      "| pos_loss_q1 | 63.4     |\n",
      "| pos_loss_q2 | 277      |\n",
      "| pos_loss_q3 | 495      |\n",
      "| samples     | 2e+04    |\n",
      "| step        | 2e+04    |\n",
      "--------------------------\n",
      "step[20000]: loss[214.44123]\n",
      "saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:00<01:13, 13.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping evaluation for now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 33.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model...\n",
      "Skipping evaluation for now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from train.training_loop import TrainLoop\n",
    "TrainLoop(args, None , model, diffusion, dataloader).run_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([78, 35])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = dataset[0].shape[0]\n",
    "num_feats = dataset[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Sampling [repetitions #0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 319.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Sampling [repetitions #1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 281.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Sampling [repetitions #2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 289.82it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_batch_size = 1\n",
    "\n",
    "all_motions = []\n",
    "for rep_i in range(args.num_repetitions):\n",
    "    print(f'### Sampling [repetitions #{rep_i}]')\n",
    "\n",
    "    sample_fn = diffusion.p_sample_loop\n",
    "\n",
    "    sample = sample_fn(\n",
    "        model,\n",
    "        (sample_batch_size, num_frames, num_feats),\n",
    "        clip_denoised=False,\n",
    "        model_kwargs={\"y\": {}},\n",
    "        skip_timesteps=0,  # 0 is the default value - i.e. don't skip any step\n",
    "        init_image=None,\n",
    "        progress=True,\n",
    "        dump_steps=None,\n",
    "        noise=None,\n",
    "        const_noise=False,\n",
    "    )\n",
    "\n",
    "    all_motions.append(sample.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 78, 35)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_motions = np.concatenate(all_motions, axis=0)\n",
    "all_motions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motion 0 saved as motion_0.npy\n",
      "Motion 1 saved as motion_1.npy\n",
      "Motion 2 saved as motion_2.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def save_motions(all_motions, output_dir):\n",
    "    for i, motion in enumerate(all_motions):\n",
    "        filename = f\"motion_{i}.npy\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        np.save(filepath, motion)\n",
    "        print(f\"Motion {i} saved as {filename}\")\n",
    "\n",
    "save_motions(all_motions, f\"/home/kenji/Fyp/DeepMimic_mujoco/diffusion/logs/{expname}/sampled_motions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
