{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "path = os.path.abspath(os.path.join('..'))\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, torch.Size([29, 69]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusion.data_loaders.backflip_dataset import BackflipMotionDataset\n",
    "dataset = BackflipMotionDataset(\"/home/kenji/Fyp/DeepMimic_mujoco/diffusion/data/motions/humanoid3d_backflip.txt\")\n",
    "len(dataset), dataset[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # not used in the final model\n",
    "        x = x + self.pe[:x.shape[0], :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TimestepEmbedder(nn.Module):\n",
    "    def __init__(self, latent_dim, sequence_pos_encoder):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.sequence_pos_encoder = sequence_pos_encoder\n",
    "\n",
    "        time_embed_dim = self.latent_dim\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim, time_embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_embed_dim, time_embed_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, timesteps):\n",
    "        return self.time_embed(self.sequence_pos_encoder.pe[timesteps])\n",
    "    \n",
    "class MotionTransformer(nn.Module):\n",
    "    def __init__(self, nfeats, latent_dim=256, ff_size=1024, num_layers=8, num_heads=4, dropout=0.1, activation=\"gelu\"):\n",
    "        super(MotionTransformer, self).__init__()\n",
    "        \n",
    "        self.nfeats = nfeats\n",
    "        self.latent_dim = latent_dim\n",
    "        self.ff_size = ff_size  \n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.inputEmbedding = nn.Linear(self.nfeats, self.latent_dim)\n",
    "        self.sequence_pos_encoder = PositionalEncoding(self.latent_dim, self.dropout)\n",
    "        self.embed_timestep = TimestepEmbedder(self.latent_dim, self.sequence_pos_encoder)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=self.latent_dim, nhead=num_heads, \n",
    "                                                    dim_feedforward=ff_size, dropout=dropout, activation=activation, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "\n",
    "        # Output Linear Layer\n",
    "        self.outputEmbedding = nn.Linear(self.latent_dim, self.nfeats)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, timesteps, y=None):\n",
    "        \"\"\"\n",
    "        x: [batch_size, max_frames, n_feats], denoted x_t in the paper\n",
    "        timesteps: [batch_size] (int)\n",
    "        \"\"\"\n",
    "        # x: [batch_size, seq_len, nfeats]\n",
    "        emb = self.embed_timestep(timesteps)  # [bs, seq_len, time_embed_dim]\n",
    "        print(\"Emb\", emb.shape)\n",
    "\n",
    "        # Input process\n",
    "        x = x.float()\n",
    "        print(x.dtype, x.shape)\n",
    "        x = self.inputEmbedding(x)  # [bs, seq_len, d]\n",
    "        print(\"Input Embedding\", x.shape)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        # adding the timestep embed\n",
    "        xseq = torch.cat((emb, x), axis=1)  # [bs, n_frames+1, d]\n",
    "        print(\"Concat x and zkx\", xseq.shape)\n",
    "\n",
    "        xseq = self.sequence_pos_encoder(xseq)  # [bs, n_frames+1, d]\n",
    "        print(\"Sequence Pos Encoder\", xseq.shape)\n",
    "        \n",
    "        output = self.transformer_encoder(xseq)[:, 1:, :]  # , src_key_padding_mask=~maskseq)  # [bs, n_frames, d]\n",
    "        print(\"Transformer Encoder\", output.shape)\n",
    "\n",
    "        # Output Linear\n",
    "        output = self.outputEmbedding(output)  # [bs, n_frames, n_feats]\n",
    "        print(\"Output Embedding\", output.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 69])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, drop_last=True)\n",
    "\n",
    "nfeats = dataset[0].shape[1]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MotionTransformer(nfeats=nfeats, latent_dim=32, ff_size=128, num_layers=8, num_heads=4, dropout=0.1, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 29, 69])\n",
      "Emb torch.Size([16, 1, 32])\n",
      "torch.float32 torch.Size([16, 29, 69])\n",
      "Input Embedding torch.Size([16, 29, 32])\n",
      "Concat x and zkx torch.Size([16, 30, 32])\n",
      "Sequence Pos Encoder torch.Size([16, 30, 32])\n",
      "Transformer Encoder torch.Size([16, 29, 32])\n",
      "Output Embedding torch.Size([16, 29, 69])\n"
     ]
    }
   ],
   "source": [
    "for it, batch in enumerate(dataloader):\n",
    "    batch = batch.to(device)\n",
    "    print(batch.shape)\n",
    "\n",
    "    model(batch, torch.arange(batch_size))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion.diffusion import gaussian_diffusion as gd\n",
    "from diffusion.diffusion.respace import SpacedDiffusion, space_timesteps\n",
    "\n",
    "def create_gaussian_diffusion(\n",
    "        diffusion_steps, # number eg 1000\n",
    "        noise_schedule, # can be 'linear', 'cosine'\n",
    "        sigma_small, # default True\n",
    "        lambda_vel, lambda_rcxyz, lambda_fc # for geometric loss, we don't have fc, default 1 for rest\n",
    "        ):\n",
    "    # default params\n",
    "    predict_xstart = True  # we always predict x_start (a.k.a. x0), that's our deal!\n",
    "    steps = diffusion_steps\n",
    "    scale_beta = 1.  # no scaling\n",
    "    timestep_respacing = ''  # can be used for ddim sampling, we don't use it.\n",
    "    learn_sigma = False\n",
    "    rescale_timesteps = False\n",
    "\n",
    "    betas = gd.get_named_beta_schedule(noise_schedule, steps, scale_beta)\n",
    "    loss_type = gd.LossType.MSE\n",
    "\n",
    "    if not timestep_respacing:\n",
    "        timestep_respacing = [steps]\n",
    "\n",
    "    return SpacedDiffusion(\n",
    "        use_timesteps=space_timesteps(steps, timestep_respacing),\n",
    "        betas=betas,\n",
    "        model_mean_type=(\n",
    "            gd.ModelMeanType.EPSILON if not predict_xstart else gd.ModelMeanType.START_X\n",
    "        ),\n",
    "        model_var_type=(\n",
    "            (\n",
    "                gd.ModelVarType.FIXED_LARGE\n",
    "                if not sigma_small\n",
    "                else gd.ModelVarType.FIXED_SMALL\n",
    "            )\n",
    "            if not learn_sigma\n",
    "            else gd.ModelVarType.LEARNED_RANGE\n",
    "        ),\n",
    "        loss_type=loss_type,\n",
    "        rescale_timesteps=rescale_timesteps,\n",
    "        lambda_vel=lambda_vel,\n",
    "        lambda_rcxyz=lambda_rcxyz,\n",
    "        lambda_fc=lambda_fc,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MotionTransformer(nfeats=nfeats, latent_dim=32, ff_size=128, num_layers=8, num_heads=4, dropout=0.1, activation=\"gelu\").to(device)\n",
    "diffusion = create_gaussian_diffusion(diffusion_steps=1000, noise_schedule=\"cosine\", sigma_small=True, lambda_vel=1, lambda_rcxyz=1, lambda_fc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultArgs:\n",
    "    def __init__(self, save_dir, model_path, eval_model_path):\n",
    "        # Base options\n",
    "        self.cuda = True\n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.seed = 10\n",
    "        self.batch_size = 64\n",
    "\n",
    "        # Diffusion options\n",
    "        self.noise_schedule = 'cosine'\n",
    "        self.diffusion_steps = 1000\n",
    "        self.sigma_small = True\n",
    "\n",
    "        # Model options\n",
    "        self.arch = 'trans_enc'\n",
    "        self.emb_trans_dec = False\n",
    "        self.layers = 8\n",
    "        self.latent_dim = 512\n",
    "        self.cond_mask_prob = 0.1\n",
    "        self.lambda_rcxyz = 0.0\n",
    "        self.lambda_vel = 0.0\n",
    "        self.lambda_fc = 0.0\n",
    "        self.unconstrained = False  # This is inferred from the 'action' parameter\n",
    "\n",
    "        # Data options\n",
    "        self.dataset = 'humanml'\n",
    "        self.data_dir = \"\"\n",
    "\n",
    "        # Training options\n",
    "        self.save_dir = save_dir\n",
    "        self.overwrite = False\n",
    "        self.train_platform_type = 'NoPlatform'\n",
    "        self.lr = 1e-4\n",
    "        self.weight_decay = 0.0\n",
    "        self.lr_anneal_steps = 0\n",
    "        self.eval_batch_size = 32\n",
    "        self.eval_split = 'test'\n",
    "        self.eval_during_training = False\n",
    "        self.eval_rep_times = 3\n",
    "        self.eval_num_samples = 1000\n",
    "        self.log_interval = 1000\n",
    "        self.save_interval = 50000\n",
    "        self.num_steps = 600000\n",
    "        self.num_frames = 60\n",
    "        self.resume_checkpoint = \"\"\n",
    "\n",
    "        # Sampling options\n",
    "        self.model_path = model_path\n",
    "        self.output_dir = ''\n",
    "        self.num_samples = 10\n",
    "        self.num_repetitions = 3\n",
    "        self.guidance_param = 2.5\n",
    "\n",
    "        # Generate options\n",
    "        self.motion_length = 6.0\n",
    "        self.input_text = ''\n",
    "        self.action_file = ''\n",
    "        self.text_prompt = ''\n",
    "        self.action_name = ''\n",
    "\n",
    "        # Edit options\n",
    "        self.edit_mode = 'in_between'\n",
    "        self.text_condition = ''\n",
    "        self.prefix_end = 0.25\n",
    "        self.suffix_start = 0.75\n",
    "\n",
    "        # Evaluation options\n",
    "        self.eval_model_path = eval_model_path\n",
    "        self.eval_mode = 'wo_mm'\n",
    "        self.eval_guidance_param = 2.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = DefaultArgs(save_dir=\"/home/kenji/Fyp/DeepMimic_mujoco/diffusion/logs/\", model_path=\"/home/kenji/Fyp/DeepMimic_mujoco/diffusion/logs/model.pt\", eval_model_path=\"/home/kenji/Fyp/DeepMimic_mujoco/diffusion/logs/model.pt\")\n",
    "args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emb torch.Size([16, 1, 32])\n",
      "torch.float32 torch.Size([16, 29, 69])\n",
      "Input Embedding torch.Size([16, 29, 32])\n",
      "Concat x and zkx torch.Size([16, 30, 32])\n",
      "Sequence Pos Encoder torch.Size([16, 30, 32])\n",
      "Transformer Encoder torch.Size([16, 29, 32])\n",
      "Output Embedding torch.Size([16, 29, 69])\n",
      "x_start.shape torch.Size([16, 29, 69])\n",
      "model_output.shape torch.Size([16, 29, 32])\n",
      "target.shape torch.Size([16, 29, 69])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/kenji/Fyp/DeepMimic_mujoco/diffusion/diffusion-exp.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-work/home/kenji/Fyp/DeepMimic_mujoco/diffusion/diffusion-exp.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining_loop\u001b[39;00m \u001b[39mimport\u001b[39;00m TrainLoop\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-work/home/kenji/Fyp/DeepMimic_mujoco/diffusion/diffusion-exp.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m TrainLoop(args, \u001b[39mNone\u001b[39;49;00m , model, diffusion, dataloader)\u001b[39m.\u001b[39;49mrun_loop()\n",
      "File \u001b[0;32m~/Fyp/DeepMimic_mujoco/diffusion/train/training_loop.py:135\u001b[0m, in \u001b[0;36mTrainLoop.run_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    134\u001b[0m motion \u001b[39m=\u001b[39m motion\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 135\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_step(motion)\n\u001b[1;32m    136\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    137\u001b[0m     \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m logger\u001b[39m.\u001b[39mget_current()\u001b[39m.\u001b[39mdumpkvs()\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Fyp/DeepMimic_mujoco/diffusion/train/training_loop.py:253\u001b[0m, in \u001b[0;36mTrainLoop.run_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_backward(batch)\n\u001b[1;32m    254\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmp_trainer\u001b[39m.\u001b[39moptimize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt)\n\u001b[1;32m    255\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_anneal_lr()\n",
      "File \u001b[0;32m~/Fyp/DeepMimic_mujoco/diffusion/train/training_loop.py:278\u001b[0m, in \u001b[0;36mTrainLoop.forward_backward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    268\u001b[0m compute_losses \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m    269\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiffusion\u001b[39m.\u001b[39mtraining_losses,\n\u001b[1;32m    270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mddp_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m     dataset\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mdataset\n\u001b[1;32m    275\u001b[0m )\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m last_batch \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_ddp:\n\u001b[0;32m--> 278\u001b[0m     losses \u001b[39m=\u001b[39m compute_losses()\n\u001b[1;32m    279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    280\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mddp_model\u001b[39m.\u001b[39mno_sync():\n",
      "File \u001b[0;32m~/Fyp/DeepMimic_mujoco/diffusion/diffusion/respace.py:97\u001b[0m, in \u001b[0;36mSpacedDiffusion.training_losses\u001b[0;34m(self, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_losses\u001b[39m(\n\u001b[1;32m     95\u001b[0m     \u001b[39mself\u001b[39m, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m     96\u001b[0m ):  \u001b[39m# pylint: disable=signature-differs\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mtraining_losses(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrap_model(model), \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Fyp/DeepMimic_mujoco/diffusion/diffusion/gaussian_diffusion.py:1307\u001b[0m, in \u001b[0;36mGaussianDiffusion.training_losses\u001b[0;34m(self, model, x_start, t, model_kwargs, noise, dataset)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmodel_output.shape\u001b[39m\u001b[39m\"\u001b[39m, model_output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m   1306\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtarget.shape\u001b[39m\u001b[39m'\u001b[39m, target\u001b[39m.\u001b[39mshape)\n\u001b[0;32m-> 1307\u001b[0m \u001b[39massert\u001b[39;00m model_output\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m target\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m x_start\u001b[39m.\u001b[39mshape  \u001b[39m# [bs, njoints, nfeats, nframes]\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \u001b[39m# terms[\"rot_mse\"] = self.masked_l2(target, model_output, mask) # mean_flat(rot_mse)\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml2_loss(target, model_output)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train.training_loop import TrainLoop\n",
    "TrainLoop(args, None , model, diffusion, dataloader).run_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
